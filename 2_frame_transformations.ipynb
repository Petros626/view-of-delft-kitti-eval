{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Frame Transformations Example\n",
    "## Outline\n",
    "[Coordinate Systems](#coordinate_systems)\n",
    "\n",
    "\n",
    "[Local coordinate transformations](#local_systems)\n",
    "\n",
    "\n",
    "[World coordinate transformations](#world_systems)\n",
    "## Loading frame information\n",
    "This step is required to use the frame transformations class. The content of this snippet is explained in Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vod.configuration import KittiLocations\n",
    "from vod.frame import FrameDataLoader\n",
    "\n",
    "kitti_locations = KittiLocations(root_dir=\"example_set\",\n",
    "                                output_dir=\"example_output\",\n",
    "                                frame_set_path=\"\",\n",
    "                                pred_dir=\"\",\n",
    "                                )\n",
    "\n",
    "frame_data = FrameDataLoader(kitti_locations=kitti_locations,\n",
    "                             frame_number=\"01201\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<a id='coordinate_systems'></a>\n",
    "## Coordinate systems\n",
    "As mentioned in notebook 1, we recorded the output of the following sensors:\n",
    "\n",
    "- ZF FRGen21 3+1D radar mounted behind the front bumper.\n",
    "- Stereo camera mounted on the windshield.\n",
    "- Velodyne HDL-64 S3 LIDAR scanner on the roof.\n",
    "\n",
    "The location of these sensors with respect to the car are presented in the figure below:\n",
    "<img src=\"Figures/Prius_sensor_setup_5.png\" alt=\"Prius sensor setup\" width=\"800\"/>\n",
    "\n",
    "This means, that each of these sensors capture information in their own coordinate system which are located with respect to each other as presented by the 3D plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vod.visualization import Visualization3D\n",
    "vis_3d = Visualization3D(frame_data, origin=\"lidar\")\n",
    "vis_3d.draw_plot(radar_origin_plot=True,\n",
    "                  lidar_origin_plot=True,\n",
    "                  camera_origin_plot=True,\n",
    "                grid_visible=True,\n",
    "                auto_frame=True)\n",
    "vis_3d.plot.camera = [5, 5, 3] + \\\n",
    "              [0, 0, 0] + \\\n",
    "              [0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='local_systems'></a>\n",
    "## Transformations between local coordinate systems\n",
    "When working with the dataset it might be necessary to transform coordinates between the different coordinate systems, for which the information for each sensor and each frame is stored in the `calib` folder. The `FrameTransformMatrix` class was created to aid the transformations between the mentioned coordinate systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vod.frame import FrameTransformMatrix\n",
    "transforms = FrameTransformMatrix(frame_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The class contains the homogenous transform matrices as properties, that takes a point cloud which is in the source frame, and transforms\n",
    " it to the target frame: `t_target_source`:\n",
    "- t_camera_lidar: from the lidar source frame, to the camera target frame.\n",
    "- t_camera_radar: from the radar source frame, to the camera target frame.\n",
    "- t_lidar_camera: from the lidar source frame, to the camera target frame.\n",
    "- t_radar_camera: from the radar source frame, to the camera target frame.\n",
    "- t_lidar_radar: from the radar source frame, to the lidar target frame.\n",
    "- t_radar_lidar: from the lidar source frame, to the radar target frame.\n",
    "\n",
    "The camera projection matrix is also available using `camera_projection_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(transforms.t_radar_lidar.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from vod.frame import homogeneous_transformation\n",
    "import numpy as np\n",
    "\n",
    "coordinate = np.array([[0, 0, 0, 1]])\n",
    "print(homogeneous_transformation(coordinate, transforms.t_radar_lidar).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='world_systems'></a>\n",
    "## Transformation to world coordinates\n",
    "\n",
    "There are three available world transformations in the `FrameTransformMatrix` class:\n",
    "- map-camera: global coordinate system.\n",
    "- odom-camera: local coordinate system.\n",
    "- UTM-camera: official UTM coordinate system.\n",
    "\n",
    "The example below shows how the transform can be used, as well as how the coordinates can be plotted to an aerial map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coordinate = np.array([[0, 0, 0, 1]])\n",
    "utm_coordinates = homogeneous_transformation(coordinate, transforms.t_utm_camera).T\n",
    "print(utm_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pdok_wms_request import AerialMapRetriever, CoordTransformer\n",
    "from pyproj import Transformer, Proj\n",
    "\n",
    "myProj = Proj(proj='utm',zone=31, ellps='WGS84', preserve_units=False)\n",
    "lon, lat = myProj(utm_coordinates[0,0], utm_coordinates[1,0], inverse=True)\n",
    "\n",
    "centre = [lon, lat] \n",
    "wh_in_m = True\n",
    "width = 70\n",
    "height = 70\n",
    "server_url = \"https://service.pdok.nl/hwh/luchtfotorgb/wms/v1_0?SERVICE=WMS&VERSION=1.3.0&REQUEST=GetMap&FORMAT=image/png&TRANSPARENT=true&LAYERS=Actueel_orthoHR&STYLES=&CRS=EPSG:28992\"\n",
    "resolution = 0.\n",
    "\n",
    "map_retriever = AerialMapRetriever(server_url, resolution=resolution)\n",
    "map_from_centre = map_retriever.get_map_from_centre(centre, width, height, resolution=resolution, wh_in_m=wh_in_m)\n",
    "map_from_centre.show(mark_center=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "view-of-delft-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
